{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteorite Landings Analysis\n",
    "### Can we predict where the next likely impact zone will be with the information given ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into a dataframe\n",
    "data = pd.read_csv(\"Meteorite_Landings.csv\")\n",
    "\n",
    "# Printing the shape of the dataset before cleaning\n",
    "print(\"Data Shape:\", data.shape)\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Basic Information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset such as the columns, data types, and number of rows\n",
    "print(\"Data Information:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics for numeric columns in the dataset\n",
    "print(\"Summary Statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Missing Values in the Dataset and Filling in the blanks or dropping them for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of missing values in each column of the dataset\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not needed\n",
    "data.drop(columns=['Unnamed: 10', 'GeoLocation'], inplace=True, errors='ignore')\n",
    "\n",
    "# Rename 'mass (g)' to 'mass' for convenience\n",
    "data.rename(columns={'mass (g)': 'mass'}, inplace=True)\n",
    "\n",
    "# Drop rows where reclat or reclong is missing\n",
    "data.dropna(subset=['reclat', 'reclong'], inplace=True)\n",
    "after_dropping_targets = data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing year values with the median year\n",
    "data['year'].fillna(data['year'].median(), inplace=True)\n",
    "\n",
    "# Fill missing mass values with the median mass\n",
    "data['mass'].fillna(data['mass'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'log-transformed mass' to handle the skewness in the mass column\n",
    "data['log_mass'] = np.log1p(data['mass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of missing values in each column of the dataset after cleaning\n",
    "print(\"Remaining Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Print the shape of the cleaned dataset\n",
    "print(\"\\nData Shape After Cleaning:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of features in the dataset\n",
    "continuous_features = ['log_mass', 'year', 'reclat', 'reclong']\n",
    "categorical_features = ['fall', 'nametype', 'recclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of categorical features\n",
    "plt.figure(figsize=(12, 10))\n",
    "for cat_col in categorical_features:\n",
    "    # Count the occurrences of each category\n",
    "    value_counts = data[cat_col].value_counts()\n",
    "    \n",
    "    # Since 'recclass' has too many categories, we will limit it to the top 10\n",
    "    value_counts = value_counts.head(10)\n",
    "    \n",
    "    # Plot the distribution of the categorical column\n",
    "    plt.subplot(2, 2, categorical_features.index(cat_col)+1)\n",
    "    plt.bar(value_counts.index, value_counts.values, color='blue', edgecolor='black')\n",
    "    plt.title(f\"Distribution of '{cat_col}'\")\n",
    "    plt.xlabel(cat_col)\n",
    "    plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms of continuous features\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, col in enumerate(continuous_features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(data[col], bins=100, color='blue', edgecolor='black')\n",
    "    plt.title(f\"Histogram of Frequency of Meteorites by {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting boxplots of continuous features\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i, col in enumerate(continuous_features):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.boxplot(data[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "    plt.xlabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Add the Cat v Cat, Con v Cat, Con v Con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set X and target variables y (assuming 'reclat' and 'reclong' are targets)\n",
    "X = data.drop(columns=['reclat', 'reclong'])\n",
    "y = data[['reclat', 'reclong']]\n",
    "\n",
    "# Convert categorical features to dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
